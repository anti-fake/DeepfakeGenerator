import argparse
import os
from typing import List

import numpy as np
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from PIL import Image
from scipy import linalg
from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm


def list_paths_recursive(root_dirs: List[str]) -> List[str]:
    """ë””ë ‰í† ë¦¬ì—ì„œ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì¬ê·€ì ìœ¼ë¡œ ìˆ˜ì§‘"""
    paths = []
    for root_dir in root_dirs:
        if os.path.isdir(root_dir):
            for file in os.listdir(root_dir):
                path = os.path.join(root_dir, file)
                paths.extend(list_paths_recursive([path]))
        else:
            if root_dir.endswith(('.png', '.jpg', '.jpeg')):
                paths.append(root_dir)
    return paths


class ImageDataset(Dataset):
    def __init__(self, root_dirs: List[str]) -> None:
        super().__init__()
        self.root_dirs = root_dirs
        self.image_paths = list_paths_recursive(root_dirs)
        self.image_paths.sort()
        self.transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Resize((299, 299), antialias=True),
        ])

    def __len__(self) -> int:
        return len(self.image_paths)

    def __getitem__(self, idx: int) -> torch.Tensor:
        image_path = self.image_paths[idx]
        image = Image.open(image_path).convert("RGB")
        image = self.transform(image)
        return image


class InceptionV3FeatureExtractor(nn.Module):
    """Inception V3 ë„¤íŠ¸ì›Œí¬ì—ì„œ 2048ì°¨ì› feature ì¶”ì¶œ"""
    def __init__(self):
        super().__init__()
        from torchvision.models import inception_v3, Inception_V3_Weights
        inception = inception_v3(weights=Inception_V3_Weights.DEFAULT)
        
        # Pool layer ì „ê¹Œì§€ì˜ ë„¤íŠ¸ì›Œí¬ ì‚¬ìš©
        self.blocks = nn.Sequential(
            inception.Conv2d_1a_3x3,
            inception.Conv2d_2a_3x3,
            inception.Conv2d_2b_3x3,
            nn.MaxPool2d(kernel_size=3, stride=2),
            inception.Conv2d_3b_1x1,
            inception.Conv2d_4a_3x3,
            nn.MaxPool2d(kernel_size=3, stride=2),
            inception.Mixed_5b,
            inception.Mixed_5c,
            inception.Mixed_5d,
            inception.Mixed_6a,
            inception.Mixed_6b,
            inception.Mixed_6c,
            inception.Mixed_6d,
            inception.Mixed_6e,
            inception.Mixed_7a,
            inception.Mixed_7b,
            inception.Mixed_7c,
            nn.AdaptiveAvgPool2d(output_size=(1, 1)),
        )
        self.eval()

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = self.blocks(x)
        x = x.view(x.size(0), -1)  # (batch_size, 2048)
        return x


def extract_features(dataloader: DataLoader, model: nn.Module, device: str) -> np.ndarray:
    """ë°ì´í„°ë¡œë”ì—ì„œ Inception feature ì¶”ì¶œ"""
    features_list = []
    model.eval()
    
    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Extracting features"):
            batch = batch.to(device)
            features = model(batch)
            features_list.append(features.cpu().numpy())
    
    return np.concatenate(features_list, axis=0)


def diagnose_fid_bottleneck(features_A: np.ndarray, features_B: np.ndarray):
    """FIDê°€ ì•ˆ ì¤„ì–´ë“œëŠ” ì›ì¸ íŒŒì•… - ìƒì„¸ ë¶„ì„"""
    
    mu_A = np.mean(features_A, axis=0)
    mu_B = np.mean(features_B, axis=0)
    sigma_A = np.cov(features_A, rowvar=False)
    sigma_B = np.cov(features_B, rowvar=False)
    
    print("=" * 60)
    print("ğŸ“Š Feature í†µê³„ ë¶„ì„")
    print("=" * 60)
    
    # ê¸°ë³¸ í†µê³„
    print(f"\n[Real Data]")
    print(f"  - ìƒ˜í”Œ ìˆ˜: {features_A.shape[0]}")
    print(f"  - Feature ì°¨ì›: {features_A.shape[1]}")
    print(f"  - í‰ê· ì˜ í‰ê· : {np.mean(mu_A):.6f}")
    print(f"  - í‰ê· ì˜ í‘œì¤€í¸ì°¨: {np.std(mu_A):.6f}")
    print(f"  - í‰ê· ì˜ ìµœì†Œ/ìµœëŒ€: [{np.min(mu_A):.6f}, {np.max(mu_A):.6f}]")
    print(f"  - ê³µë¶„ì‚° ëŒ€ê° í‰ê· : {np.mean(np.diag(sigma_A)):.6f}")
    print(f"  - ê³µë¶„ì‚° Frobenius norm: {np.linalg.norm(sigma_A, 'fro'):.6f}")
    
    print(f"\n[Generated Data]")
    print(f"  - ìƒ˜í”Œ ìˆ˜: {features_B.shape[0]}")
    print(f"  - Feature ì°¨ì›: {features_B.shape[1]}")
    print(f"  - í‰ê· ì˜ í‰ê· : {np.mean(mu_B):.6f}")
    print(f"  - í‰ê· ì˜ í‘œì¤€í¸ì°¨: {np.std(mu_B):.6f}")
    print(f"  - í‰ê· ì˜ ìµœì†Œ/ìµœëŒ€: [{np.min(mu_B):.6f}, {np.max(mu_B):.6f}]")
    print(f"  - ê³µë¶„ì‚° ëŒ€ê° í‰ê· : {np.mean(np.diag(sigma_B)):.6f}")
    print(f"  - ê³µë¶„ì‚° Frobenius norm: {np.linalg.norm(sigma_B, 'fro'):.6f}")
    
    # í‰ê·  ì°¨ì´ ë¶„ì„
    mean_diff = mu_A - mu_B
    print(f"\n[í‰ê·  ì°¨ì´ ë¶„ì„]")
    print(f"  - í‰ê·  ì°¨ì´ì˜ L2 norm: {np.linalg.norm(mean_diff):.6f}")
    print(f"  - í‰ê·  ì°¨ì´ì˜ í‰ê· : {np.mean(mean_diff):.6f}")
    print(f"  - í‰ê·  ì°¨ì´ì˜ í‘œì¤€í¸ì°¨: {np.std(mean_diff):.6f}")
    print(f"  - í‰ê·  ì°¨ì´ì˜ ìµœì†Œ/ìµœëŒ€: [{np.min(mean_diff):.6f}, {np.max(mean_diff):.6f}]")
    
    # ê°€ì¥ í° ì°¨ì´ë¥¼ ë³´ì´ëŠ” ì°¨ì›ë“¤
    top_k = 10
    top_diff_indices = np.argsort(np.abs(mean_diff))[-top_k:][::-1]
    print(f"  - ìƒìœ„ {top_k}ê°œ ì°¨ì´ ì°¨ì›: {top_diff_indices}")
    print(f"  - ìƒìœ„ {top_k}ê°œ ì°¨ì´ ê°’: {mean_diff[top_diff_indices]}")
    
    # ê³µë¶„ì‚° ì°¨ì´ ë¶„ì„
    cov_diff = sigma_A - sigma_B
    print(f"\n[ê³µë¶„ì‚° ì°¨ì´ ë¶„ì„]")
    print(f"  - ê³µë¶„ì‚° ì°¨ì´ Frobenius norm: {np.linalg.norm(cov_diff, 'fro'):.6f}")
    print(f"  - ëŒ€ê° ìš”ì†Œ ì°¨ì´ì˜ í‰ê· : {np.mean(np.diag(cov_diff)):.6f}")
    print(f"  - ëŒ€ê° ìš”ì†Œ ì°¨ì´ì˜ í‘œì¤€í¸ì°¨: {np.std(np.diag(cov_diff)):.6f}")
    
    # Eigenvalue ë¶„ì„
    eigvals_A = np.linalg.eigvalsh(sigma_A)
    eigvals_B = np.linalg.eigvalsh(sigma_B)
    print(f"\n[Eigenvalue ë¶„ì„]")
    print(f"  - Real ìƒìœ„ 10ê°œ eigenvalues: {eigvals_A[-10:][::-1]}")
    print(f"  - Gen ìƒìœ„ 10ê°œ eigenvalues: {eigvals_B[-10:][::-1]}")
    print(f"  - Real eigenvalue í•©: {np.sum(eigvals_A):.6f}")
    print(f"  - Gen eigenvalue í•©: {np.sum(eigvals_B):.6f}")
    
    # FID ë¶„í•´
    print("\n" + "=" * 60)
    print("ğŸ“ˆ FID ë¶„í•´ ë¶„ì„")
    print("=" * 60)
    
    mean_term = np.sum((mu_A - mu_B) ** 2)
    
    # sqrt(sigma_A @ sigma_B) ê³„ì‚°
    covmean = linalg.sqrtm(sigma_A @ sigma_B)
    if np.iscomplexobj(covmean):
        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):
            print("  âš ï¸ ê²½ê³ : covmeanì— ìœ ì˜ë¯¸í•œ í—ˆìˆ˜ë¶€ê°€ ìˆìŒ")
        covmean = covmean.real
    
    cov_term = np.trace(sigma_A + sigma_B - 2 * covmean)
    
    total_fid = mean_term + cov_term
    
    print(f"\n  í‰ê·  ì°¨ì´ ê¸°ì—¬ (mean term): {mean_term:.4f} ({100*mean_term/total_fid:.1f}%)")
    print(f"  ê³µë¶„ì‚° ì°¨ì´ ê¸°ì—¬ (cov term): {cov_term:.4f} ({100*cov_term/total_fid:.1f}%)")
    print(f"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    print(f"  ì´ FID: {total_fid:.4f}")
    
    # ê°œì„  ë°©í–¥ ì œì•ˆ
    print("\n" + "=" * 60)
    print("ğŸ’¡ ë¶„ì„ ê²°ê³¼ ìš”ì•½")
    print("=" * 60)
    
    if mean_term > cov_term:
        print(f"\n  â†’ í‰ê·  ì°¨ì´ê°€ FIDì˜ ì£¼ìš” ì›ì¸ ({100*mean_term/total_fid:.1f}%)")
        print("  â†’ ìƒì„± ì´ë¯¸ì§€ì˜ ì „ë°˜ì ì¸ ìƒ‰ìƒ, ë°ê¸°, ë˜ëŠ” ìŠ¤íƒ€ì¼ì´ ì‹¤ì œì™€ ë‹¤ë¦„")
    else:
        print(f"\n  â†’ ê³µë¶„ì‚° ì°¨ì´ê°€ FIDì˜ ì£¼ìš” ì›ì¸ ({100*cov_term/total_fid:.1f}%)")
        print("  â†’ ìƒì„± ì´ë¯¸ì§€ì˜ ë‹¤ì–‘ì„± ë˜ëŠ” feature ê°„ ìƒê´€ê´€ê³„ê°€ ì‹¤ì œì™€ ë‹¤ë¦„")
    
    return {
        'mean_term': mean_term,
        'cov_term': cov_term,
        'total_fid': total_fid,
        'mu_real': mu_A,
        'mu_gen': mu_B,
        'sigma_real': sigma_A,
        'sigma_gen': sigma_B,
    }


def main(args):
    print(f"Real ë°ì´í„° ê²½ë¡œ: {args.real_dir}")
    print(f"Generated ë°ì´í„° ê²½ë¡œ: {args.gen_dir}")
    print(f"Device: {args.device}")
    print(f"Batch size: {args.batch_size}")
    
    # ë°ì´í„°ì…‹ ë¡œë“œ
    real_dataset = ImageDataset([args.real_dir])
    gen_dataset = ImageDataset([args.gen_dir])
    
    print(f"\nReal ì´ë¯¸ì§€ ìˆ˜: {len(real_dataset)}")
    print(f"Generated ì´ë¯¸ì§€ ìˆ˜: {len(gen_dataset)}")
    
    real_loader = DataLoader(real_dataset, batch_size=args.batch_size, 
                             shuffle=False, num_workers=args.num_workers)
    gen_loader = DataLoader(gen_dataset, batch_size=args.batch_size, 
                            shuffle=False, num_workers=args.num_workers)
    
    # Feature extractor ë¡œë“œ
    print("\nInception V3 ëª¨ë¸ ë¡œë”©...")
    model = InceptionV3FeatureExtractor()
    model.to(args.device)
    
    # Feature ì¶”ì¶œ
    print("\nReal ë°ì´í„° feature ì¶”ì¶œ ì¤‘...")
    features_real = extract_features(real_loader, model, args.device)
    
    print("\nGenerated ë°ì´í„° feature ì¶”ì¶œ ì¤‘...")
    features_gen = extract_features(gen_loader, model, args.device)
    
    print(f"\nReal features shape: {features_real.shape}")
    print(f"Generated features shape: {features_gen.shape}")
    
    # FID ë¶„ì„
    results = diagnose_fid_bottleneck(features_real, features_gen)
    
    # ê²°ê³¼ ì €ì¥ (ì˜µì…˜)
    if args.save_features:
        save_path = args.save_features
        np.savez(save_path, 
                 features_real=features_real, 
                 features_gen=features_gen,
                 mu_real=results['mu_real'],
                 mu_gen=results['mu_gen'],
                 sigma_real=results['sigma_real'],
                 sigma_gen=results['sigma_gen'])
        print(f"\nâœ… Features ì €ì¥ë¨: {save_path}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="FID ë¶„ì„: í‰ê· ê³¼ ê³µë¶„ì‚° ë¹„êµ")
    parser.add_argument("--real_dir", type=str, required=True, 
                        help="Real ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ")
    parser.add_argument("--gen_dir", type=str, required=True, 
                        help="Generated ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ")
    parser.add_argument("--batch_size", type=int, default=32, 
                        help="Batch size (default: 32)")
    parser.add_argument("--device", type=str, 
                        default="cuda" if torch.cuda.is_available() else "cpu",
                        help="Device (default: cuda if available)")
    parser.add_argument("--num_workers", type=int, default=8,
                        help="DataLoader workers (default: 8)")
    parser.add_argument("--save_features", type=str, default=None,
                        help="Feature ì €ì¥ ê²½ë¡œ (.npz)")
    
    args = parser.parse_args()
    main(args)
